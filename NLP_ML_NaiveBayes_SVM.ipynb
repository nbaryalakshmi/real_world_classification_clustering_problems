{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>play game half half game point scored play ran...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper front front paper issue paper error numb...</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>firework security leave midnight midnight ligh...</td>\n",
       "      <td>Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>commercial traffic flight passenger midnight t...</td>\n",
       "      <td>Recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>television television program program show pro...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              corpus       label\n",
       "0  play game half half game point scored play ran...      Sports\n",
       "1  paper front front paper issue paper error numb...   Computers\n",
       "2  firework security leave midnight midnight ligh...     Society\n",
       "3  commercial traffic flight passenger midnight t...  Recreation\n",
       "4  television television program program show pro...        Arts"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get labelled data\n",
    "df_data=pd.read_csv('corpus_labels.csv')\n",
    "df_data=df_data[['corpus','category']]\n",
    "df_data.rename(columns={'category':'label'}, inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training data: (866,) (866,)\n",
      "Number of records in testing data: (217,) (217,)\n"
     ]
    }
   ],
   "source": [
    "#Split data to training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data['corpus'], df_data['label'], \n",
    "                                                    test_size=0.2, random_state=4)\n",
    "print ('Number of records in training data:', X_train.shape,  y_train.shape)\n",
    "print ('Number of records in testing data:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Classification NAIVE BAYES #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time(seconds) taken to train naive bayes model: 0.09142184257507324\n",
      "Accuracy Score: 0.7188940092165899\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Arts       1.00      0.42      0.59        24\n",
      "    Business       0.94      0.62      0.75        24\n",
      "   Computers       0.93      0.81      0.87        16\n",
      "       Games       0.00      0.00      0.00         2\n",
      "      Health       1.00      0.14      0.25         7\n",
      "        Home       1.00      0.40      0.57         5\n",
      "  Recreation       0.00      0.00      0.00        13\n",
      "     Science       0.00      0.00      0.00         3\n",
      "     Society       0.60      1.00      0.75        82\n",
      "      Sports       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.72       217\n",
      "   macro avg       0.63      0.42      0.46       217\n",
      "weighted avg       0.73      0.72      0.68       217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Feed data vectorizer, transformer and naive bayes classifier object to a pipeline\n",
    "time_start=time()\n",
    "obj_pipeline = Pipeline([('vect', TfidfVectorizer()), ('tfidf', TfidfTransformer()), \n",
    "                         ('clf', MultinomialNB())])\n",
    "obj_pipeline.fit(X_train, y_train)\n",
    "time_taken=time()-time_start\n",
    "print('Time(seconds) taken to train naive bayes model:',time_taken)\n",
    "#Predict values using test data\n",
    "predicted_values = obj_pipeline.predict(X_test)\n",
    "print('Accuracy Score: %s' % accuracy_score(predicted_values, y_test))\n",
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arts', 'Business', 'Society', 'Society', 'Society'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted values\n",
    "predicted_values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6752658734289885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1-score\n",
    "print('f1-score')\n",
    "f1_score(y_test, predicted_values, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard-score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5460346270345445"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jaccard-score\n",
    "print('jaccard-score')\n",
    "jaccard_score(y_test, predicted_values, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Classification SVM #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time(seconds) taken to train SVM model: 0.07739925384521484\n",
      "Accuracy Score: 0.8064516129032258\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Arts       0.67      0.75      0.71        24\n",
      "    Business       0.88      0.92      0.90        24\n",
      "   Computers       0.94      0.94      0.94        16\n",
      "       Games       0.50      0.50      0.50         2\n",
      "      Health       0.56      0.71      0.63         7\n",
      "        Home       0.67      0.40      0.50         5\n",
      "  Recreation       0.60      0.23      0.33        13\n",
      "     Science       0.60      1.00      0.75         3\n",
      "     Society       0.83      0.91      0.87        82\n",
      "      Sports       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.81       217\n",
      "   macro avg       0.71      0.71      0.69       217\n",
      "weighted avg       0.80      0.81      0.80       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feed data vectorizer, transformer and SVM classifier object to a pipeline\n",
    "time_start=time()\n",
    "objPipelineSvm = Pipeline([('vect', TfidfVectorizer()), ('tfidf', TfidfTransformer()), \n",
    "                           ('clf', LinearSVC())])\n",
    "objPipelineSvm.fit(X_train, y_train)\n",
    "time_taken=time()-time_start\n",
    "print('Time(seconds) taken to train SVM model:',time_taken)\n",
    "#Predict values using test data\n",
    "predicted_values = objPipelineSvm.predict(X_test)\n",
    "print('Accuracy Score: %s' % accuracy_score(predicted_values, y_test))\n",
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7968180946549042"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1-score\n",
    "print('f1-score')\n",
    "f1_score(y_test, predicted_values, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard-score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6835288917997892"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jaccard-score\n",
    "print('jaccard-score')\n",
    "jaccard_score(y_test, predicted_values, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### END #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
